{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5737a66-1bd1-46ec-8e4d-b93b31161662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gbmi.exp_modular_fine_tuning.train import MODULAR_ADDITION_113_CLOCK_CONFIG\n",
    "from gbmi.exp_modular_fine_tuning.train import ModularFineTuningTrainingWrapper\n",
    "from gbmi.model import train_or_load_model\n",
    "import torch\n",
    "import einops\n",
    "from torch import tensor\n",
    "from math import *\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "969de5aa-d4b7-4730-ad5c-2d447fba4891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0938cd15-21af-4181-a8ae-3729c4956dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HookedTransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0): TransformerBlock(\n",
       "      (ln1): Identity()\n",
       "      (ln2): Identity()\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = MODULAR_ADDITION_113_CLOCK_CONFIG\n",
    "runtime, model = train_or_load_model(config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80866175-d018-4a6e-8fcb-1738e13de1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "embedding_matrix = model.embed.W_E.clone()\n",
    "embedding_matrix.requires_grad = False\n",
    "model.embed = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "901690ff-2479-4206-8018-024f6c926aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(logits,labels):\n",
    "    print(logits.shape)\n",
    "    if len(logits.shape)==3:\n",
    "        logits = logits[:,:, -1]\n",
    "    logits = logits.to(torch.float64)\n",
    "    log_probs = logits.log_softmax(dim=-1)\n",
    "    correct_log_probs = log_probs.gather(dim=-1, index=labels[:, None])[:, 0]\n",
    "    return -correct_log_probs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "609c64a6-8ecd-4a29-9f68-0c9bf51112dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-6.1755, -0.9262,  0.4199],\n",
      "         [ 8.8307,  2.8965,  1.1911],\n",
      "         [ 0.6976,  0.2317,  0.9714],\n",
      "         ...,\n",
      "         [ 4.6736,  2.9706,  0.2907],\n",
      "         [-9.5380, -1.7593, -1.5765],\n",
      "         [-1.0700, -0.4691,  0.0631]],\n",
      "\n",
      "        [[-0.3219, -1.7656, -1.2217],\n",
      "         [ 4.9145,  2.5245,  0.6075],\n",
      "         [ 0.1035,  0.4361,  0.5748],\n",
      "         ...,\n",
      "         [ 4.8511,  3.5585,  0.9854],\n",
      "         [-7.0302, -2.4302, -0.7050],\n",
      "         [-2.3406,  0.6992,  2.8796]]], device='cuda:0',\n",
      "       grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "p = 113\n",
    "q = 2*p\n",
    "class DifferentModClock(torch.nn.Module):\n",
    "    def __init__(self,q):\n",
    "        super(DifferentModClock,self).__init__()\n",
    "        self.W_e = torch.nn.Parameter(-0.5/sqrt(p+1) + torch.rand((q+1,p+1))/sqrt(p+1)).to(device)\n",
    "        self.W_u = torch.nn.Parameter(-0.5/sqrt(p) + torch.rand((q,p))/sqrt(p)).to(device)\n",
    "        self.params = torch.nn.ParameterList([self.W_e,self.W_u])\n",
    "    def forward(self,x):\n",
    "        z = torch.nn.functional.one_hot(x.to(device)).to(torch.float)\n",
    "        \n",
    "        y = z @ self.W_e @ embedding_matrix\n",
    "        if(len(y.shape)!=3):\n",
    "            y = y.unsqueeze(0)\n",
    "        return self.W_u @ (einops.rearrange(model(y),\"b d p -> b p d\"))\n",
    "clock = DifferentModClock(q)\n",
    "\n",
    "print(clock(torch.tensor([[1,2,226],[2,5,226]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "23111000-d93f-44af-a8c1-30a2ead4187a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51076, 3])\n"
     ]
    }
   ],
   "source": [
    "a_vector = einops.repeat(torch.arange(q), \"i -> (i j)\", j=q)\n",
    "b_vector = einops.repeat(torch.arange(q), \"j -> (i j)\", i=q)\n",
    "equals_vector = einops.repeat(torch.tensor(q), \" -> (i j)\", i=q, j=q)\n",
    "dataset = torch.stack([a_vector, b_vector, equals_vector], dim=1).to(device)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3cfcdbf7-49f4-431f-9781-9f187aaf4293",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim =torch.optim.AdamW(clock.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fa0c0f06-6b35-4084-9e03-9171522d4e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock.W_e.retain_grad()\n",
    "def run_batch(x):\n",
    "        labels = (x[:, 0] + x[:, 1]) % q\n",
    "\n",
    "        y_preds = clock(x)\n",
    "\n",
    "        loss = loss_fn(y_preds, labels)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fae6e101-b1be-4987-9c8a-09109fc2479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51076, 226, 3])\n",
      "tensor(11.5251, device='cuda:0', dtype=torch.float64, grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(11.5251, device='cuda:0', dtype=torch.float64, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_batch(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
