{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2386d8d3-1da0-4a9b-b61c-184684bb3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gbmi.utils import ein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c69c5e1f-f702-4d2a-9bb9-1767181aeb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.rand(4, 5)\n",
    "B = torch.rand(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6aa820e-727f-431c-9a89-4a8554b6342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "graph = None\n",
    "\n",
    "\n",
    "def custom_backend(gm: torch.fx.GraphModule, example_inputs: List[torch.Tensor]):\n",
    "    global graph\n",
    "    print(\"custom backend called with FX graph:\")\n",
    "    graph = gm\n",
    "    return gm.forward\n",
    "\n",
    "\n",
    "# Reset since we are using a different backend.\n",
    "torch._dynamo.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec922407-7aca-4f5c-9ce6-3f7f90908571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return A @ x\n",
    "\n",
    "\n",
    "opt_model = torch.compile(model, backend=custom_backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2589895f-c8f3-4ad0-aad8-e25d78b704b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom backend called with FX graph:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.7709, 1.8965, 1.5195, 1.8628, 1.0387, 1.9042],\n",
       "        [0.6951, 1.5685, 0.9689, 1.2673, 0.9519, 1.4195],\n",
       "        [0.6140, 1.7981, 1.1005, 1.3455, 1.0335, 1.4959],\n",
       "        [0.9975, 1.7626, 1.0959, 1.4170, 0.8062, 1.4095]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_model(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "939adccb-de10-4d64-97f2-b6dd5ccd391b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Graph' object has no attribute 'node'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Graph' object has no attribute 'node'"
     ]
    }
   ],
   "source": [
    "graph.graph.node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3696d5-1403-42c5-b3fa-f6b17310c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "ein.array(lambda i: torch.exp(i) + B[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e28a4534-a0be-42ce-92b8-643a3a1875ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "038b00f2-528c-49ee-9fe8-1d47a0371dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstraintTrackingTensor(torch.Tensor):\n",
    "    @staticmethod\n",
    "    def add_constraint(tensor, size):\n",
    "        if hasattr(tensor, \"_constraints\"):\n",
    "            tensor._constraints.add(size)\n",
    "        else:\n",
    "            tensor._constraints = {size}\n",
    "\n",
    "    @classmethod\n",
    "    def __torch_function__(cls, func, types, args=(), kwargs=None):\n",
    "        if func.__name__ == \"__getitem__\":\n",
    "            for size, index in zip(args[0].shape, args[1]):\n",
    "                ConstraintTrackingTensor.add_constraint(index, size)\n",
    "        if kwargs is None:\n",
    "            kwargs = {}\n",
    "        return super().__torch_function__(func, types, args, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff7e7fb-4760-4fc0-ae67-0efdac21677e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7584f569-7b77-40b7-bd77-ce2cc562fedb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3027892808.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    (lambda j)(idx)\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "idx = ConstraintTrackingTensor(torch.tensor(0))\n",
    "(lambda j)(idx)\n",
    "idx._constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa6e2fdb-5f17-485e-8f05-bcc1d864da7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43midx\u001b[49m\u001b[38;5;241m.\u001b[39m_constraints\n",
      "\u001b[0;31mNameError\u001b[0m: name 'idx' is not defined"
     ]
    }
   ],
   "source": [
    "idx._constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07e49a14-effd-439a-8e51-06f03e7ede9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataTensor(object):\n",
    "    def __init__(self, data, metadata=None, **kwargs):\n",
    "        self._t = torch.as_tensor(data, **kwargs)\n",
    "        self._metadata = metadata\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Metadata:\\n{}\\n\\ndata:\\n{}\".format(self._metadata, self._t)\n",
    "\n",
    "    @classmethod\n",
    "    def __torch_function__(cls, func, types, args=(), kwargs=None):\n",
    "        print(\"---\")\n",
    "        print(cls, func)\n",
    "        print(\"===\")\n",
    "        for i in args:\n",
    "            print(\"+++\")\n",
    "            print(i)\n",
    "        if kwargs is None:\n",
    "            kwargs = {}\n",
    "        args_flat = torch.utils._pytree.tree_flatten(args)[0]\n",
    "        print(\"flat\", args_flat)\n",
    "        metadatas = tuple(a._metadata for a in args_flat if hasattr(a, \"_metadata\"))\n",
    "        print(\"m\", metadatas)\n",
    "        args = torch.utils._pytree.tree_map(lambda x: getattr(x, \"_t\", x), args)\n",
    "        ret = func(*args, **kwargs)\n",
    "        return MetadataTensor(ret, metadata=metadatas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bb1a719-9a0b-4030-a601-e99d51ec025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\"owner\": \"Ministry of Silly Walks\"}\n",
    "m = MetadataTensor(1, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4c2d5883-626c-4861-b0f4-7d2e4fc1f0df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "<class '__main__.MetadataTensor'> <built-in method exp of type object at 0x118d3a9b8>\n",
      "===\n",
      "+++\n",
      "Metadata:\n",
      "x\n",
      "\n",
      "data:\n",
      "0\n",
      "flat [Metadata:\n",
      "x\n",
      "\n",
      "data:\n",
      "0]\n",
      "m ('x',)\n",
      "---\n",
      "<class '__main__.MetadataTensor'> <slot wrapper '__getitem__' of 'torch._C.TensorBase' objects>\n",
      "===\n",
      "+++\n",
      "tensor([[4.3073e-01, 1.0403e-01, 2.3399e-01, 6.8633e-01, 5.2392e-01, 4.5291e-01],\n",
      "        [1.5897e-01, 9.5502e-01, 4.0753e-01, 2.8613e-01, 4.4343e-01, 8.0154e-01],\n",
      "        [3.4549e-01, 3.7140e-01, 1.0447e-01, 8.2847e-01, 3.9709e-04, 9.5640e-01],\n",
      "        [7.1253e-01, 3.9568e-01, 2.2937e-01, 4.5929e-01, 5.2071e-01, 8.7025e-01],\n",
      "        [2.3285e-01, 6.2969e-02, 8.1768e-01, 3.2309e-01, 6.9715e-03, 9.8854e-01]])\n",
      "+++\n",
      "(Metadata:\n",
      "x\n",
      "\n",
      "data:\n",
      "0,)\n",
      "flat [tensor([[4.3073e-01, 1.0403e-01, 2.3399e-01, 6.8633e-01, 5.2392e-01, 4.5291e-01],\n",
      "        [1.5897e-01, 9.5502e-01, 4.0753e-01, 2.8613e-01, 4.4343e-01, 8.0154e-01],\n",
      "        [3.4549e-01, 3.7140e-01, 1.0447e-01, 8.2847e-01, 3.9709e-04, 9.5640e-01],\n",
      "        [7.1253e-01, 3.9568e-01, 2.2937e-01, 4.5929e-01, 5.2071e-01, 8.7025e-01],\n",
      "        [2.3285e-01, 6.2969e-02, 8.1768e-01, 3.2309e-01, 6.9715e-03, 9.8854e-01]]), Metadata:\n",
      "x\n",
      "\n",
      "data:\n",
      "0]\n",
      "m ('x',)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'MetadataTensor' and 'MetadataTensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMetadataTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[147], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (\u001b[38;5;28;01mlambda\u001b[39;00m i: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)(MetadataTensor(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0\u001b[39m), metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'MetadataTensor' and 'MetadataTensor'"
     ]
    }
   ],
   "source": [
    "(lambda i: torch.exp(i) + B[i])(MetadataTensor(torch.tensor(0), metadata=\"x\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0a8f0344-3600-47f9-b263-2ee7de6240ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__getitem__'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f731c093-7158-435c-84bb-43f77baa87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def f(i):\n",
    "    x = torch.exp(i) + B[i]\n",
    "    return x, i\n",
    "\n",
    "\n",
    "#  To avoid dealing with prim::Bailout stuff\n",
    "torch._C._jit_set_profiling_executor(False)\n",
    "\n",
    "trace = torch.jit.trace(f, torch.tensor(1, dtype=torch.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94887b22-6f33-4685-9b33-bdaa548efb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%i : Int(requires_grad=0, device=cpu)):\n",
       "  %2 : int = aten::Int(%i)\n",
       "  %1 : Float(requires_grad=0, device=cpu) = aten::exp(%i) # /var/folders/y1/33lbjdps12lf6x0csm_rvb5m0000gn/T/ipykernel_21548/588144388.py:4:0\n",
       "  %3 : Float(5, 6, strides=[6, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /var/folders/y1/33lbjdps12lf6x0csm_rvb5m0000gn/T/ipykernel_21548/588144388.py:4:0\n",
       "  %4 : int = prim::Constant[value=0]() # /var/folders/y1/33lbjdps12lf6x0csm_rvb5m0000gn/T/ipykernel_21548/588144388.py:4:0\n",
       "  %5 : Float(6, strides=[1], requires_grad=0, device=cpu) = aten::select(%3, %4, %2) # /var/folders/y1/33lbjdps12lf6x0csm_rvb5m0000gn/T/ipykernel_21548/588144388.py:4:0\n",
       "  %6 : int = prim::Constant[value=1]() # /var/folders/y1/33lbjdps12lf6x0csm_rvb5m0000gn/T/ipykernel_21548/588144388.py:4:0\n",
       "  %7 : Float(6, strides=[1], requires_grad=0, device=cpu) = aten::add(%1, %5, %6) # /var/folders/y1/33lbjdps12lf6x0csm_rvb5m0000gn/T/ipykernel_21548/588144388.py:4:0\n",
       "  %8 : (Float(6, strides=[1], requires_grad=0, device=cpu), Int(requires_grad=0, device=cpu)) = prim::TupleConstruct(%7, %i)\n",
       "  return (%8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c38ba-0585-45ec-be94-06b54746138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda f_plus: f_plus(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "61cf897a-1c18-4ea9-9c18-8f3cc096431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe853a03-4860-4506-89f2-1b8042f4b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x, y: y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b7b89be8-9035-4af4-8dbb-1684a395c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff597b0b-7f79-4022-aa20-137f9e81ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_hash = lambda x: hashlib.md5(cloudpickle.dumps(x)).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "af3a0656-b3fd-4481-bdfc-316ee4de0e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a48b469abf481a30a9506aa7425741ea'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_hash(functools.partial(f, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2bb3ecf2-a3b5-454c-b83f-e14be1b4cbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a4a99bc6fd85f16d5f49d1249a87d04f'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashlib.md5(cloudpickle.dumps((lambda x: lambda y: 5)(4))).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7c712447-e83b-4c33-b44f-2919761952f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generic, TypeVar\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "class ContextualGlobal(Generic[T]):\n",
    "    def __init__(self, val: T):\n",
    "        self.vals = [val]\n",
    "\n",
    "    @contextmanager\n",
    "    def set(self, val: T):\n",
    "        self.vals.append(val)\n",
    "        yield\n",
    "        self.vals.pop()\n",
    "\n",
    "    def get(self) -> T:\n",
    "        return self.vals[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c8b0d049-7b5d-473a-8d71-025e671b5a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ContextualGlobal(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "74a981c7-1875-4f15-bc6f-f5dac7dbf7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "with g.set(2):\n",
    "    with g.set(3):\n",
    "        print(g.get())\n",
    "    print(g.get())\n",
    "print(g.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "82f29035-1405-4ed8-a007-1e632c39b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_contents(func):\n",
    "    closure = (\n",
    "        tuple(cell.cell_contents for cell in func.__closure__)\n",
    "        if getattr(func, \"__closure__\", None)\n",
    "        else ()\n",
    "    )\n",
    "    return (\n",
    "        func.__name__,\n",
    "        func.__defaults__,\n",
    "        closure,\n",
    "        func.__code__.co_code,\n",
    "        func.__code__.co_consts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e797575-e4cb-4cd7-bcd0-6f14f3a8e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8dc1851-144e-4380-be4d-7ac0100b0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e5e1b38d-9720-49d4-9e72-9ed109e90123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import copyreg\n",
    "import functorch.dim\n",
    "\n",
    "\n",
    "class Pickler(dill.Pickler):\n",
    "    def reducer_override(self, obj):\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            if \"BatchedTensor\" in repr(obj):\n",
    "                return pickle.loads, (\n",
    "                    pickle.dumps(torch._C._functorch.get_unwrapped(obj)),\n",
    "                )\n",
    "            return NotImplemented\n",
    "        elif isinstance(obj, functorch.dim.Tensor):\n",
    "            return pickle.loads, (\n",
    "                pickle.dumps(\n",
    "                    obj.order(*obj.dims),\n",
    "                )\n",
    "            )\n",
    "        return NotImplemented\n",
    "\n",
    "\n",
    "def dumps(obj):\n",
    "    f = io.BytesIO()\n",
    "    p = Pickler(f)\n",
    "    p.dump(obj)\n",
    "    return f.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a25fdc73-656f-416a-b60d-a6d3d04479e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8632, 0.3194, 0.7590,  ..., 0.3651, 0.4767, 0.4451])\n"
     ]
    }
   ],
   "source": [
    "v = dumps(torch.rand(100000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bf299408-f0a9-4b1f-a729-57402e2f7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functorch.dim import dims\n",
    "\n",
    "dim1, dim2 = dims(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f4819b52-33ee-46bf-980b-d9d47fda9aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[[[1, 2]], [[3, 4]]]])[dim1, dim2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c9fa100d-ff9a-4b20-87bf-ad13defc9aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functorch.dim.Tensor"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4797713f-39fb-4552-8ea2-b1adc0da0367",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 2]],\n",
       "\n",
       "         [[3, 4]]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.order(*t.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "743c4b7b-13f8-45f2-9a9c-6d20750df254",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No wrappers present!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_unwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No wrappers present!"
     ]
    }
   ],
   "source": [
    "torch._C._functorch.get_unwrapped(torch.tensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e99c25e-ac6f-4375-a6c0-aaa9bbd29cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x04\\x95$\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\ndill._dill\\x94\\x8c\\x10_create_function\\x94\\x93\\x94(h\\x00\\x8c\\x0c_create_code\\x94\\x93\\x94(C\\x00\\x94K\\x01K\\x00K\\x00K\\x01K\\x02KCC\\x08|\\x00t\\x00\\x17\\x00S\\x00\\x94N\\x85\\x94\\x8c\\x01u\\x94\\x85\\x94\\x8c\\x01x\\x94\\x85\\x94\\x8cN/var/folders/y1/33lbjdps12lf6x0csm_rvb5m0000gn/T/ipykernel_42541/3750004189.py\\x94\\x8c\\x08<lambda>\\x94K\\x01C\\x02\\x08\\x00\\x94))t\\x94R\\x94c__builtin__\\n__main__\\nh\\rNNt\\x94R\\x94}\\x94}\\x94\\x8c\\x0f__annotations__\\x94}\\x94s\\x86\\x94b\\x8c\\x05torch\\x94\\x8c\\x06Tensor\\x94\\x93\\x94\\x8a\\x05 >\\x04\\x8b\\x02\\x85\\x94R\\x94\\x86\\x94.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumps(((lambda x: x + u), u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59d34ef9-ca01-46a8-b1b4-c6a09ec0974e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cloudpickle.cloudpickle.Pickler"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloudpickle.Pickler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6557e3d7-ac64-468c-830d-f5889f80d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudpickle.Pickler.dispatch_table[torch.Tensor] = lambda x: (torch.Tensor, (hash(x),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c8b0a0a-4c54-49ca-a971-ab2668caab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29501fec-cc39-4466-9efb-f86e71d76375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x80\\x05\\x95\\xf9\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x17cloudpickle.cloudpickle\\x94\\x8c\\x0e_make_function\\x94\\x93\\x94(h\\x00\\x8c\\r_builtin_type\\x94\\x93\\x94\\x8c\\x08CodeType\\x94\\x85\\x94R\\x94(K\\x01K\\x00K\\x00K\\x01K\\x02KCC\\x08t\\x00|\\x00\\x17\\x00S\\x00\\x94N\\x85\\x94\\x8c\\x01x\\x94\\x85\\x94\\x8c\\x01y\\x94\\x85\\x94\\x8cN/var/folders/y1/33lbjdps12lf6x0csm_rvb5m0000gn/T/ipykernel_42541/2147222178.py\\x94\\x8c\\x08<lambda>\\x94K\\x04C\\x02\\x08\\x00\\x94))t\\x94R\\x94}\\x94(\\x8c\\x0b__package__\\x94N\\x8c\\x08__name__\\x94\\x8c\\x08__main__\\x94uNNNt\\x94R\\x94h\\x00\\x8c\\x12_function_setstate\\x94\\x93\\x94h\\x18}\\x94}\\x94(h\\x15h\\x0f\\x8c\\x0c__qualname__\\x94h\\x0f\\x8c\\x0f__annotations__\\x94}\\x94\\x8c\\x0e__kwdefaults__\\x94N\\x8c\\x0c__defaults__\\x94N\\x8c\\n__module__\\x94h\\x16\\x8c\\x07__doc__\\x94N\\x8c\\x0b__closure__\\x94N\\x8c\\x17_cloudpickle_submodules\\x94]\\x94\\x8c\\x0b__globals__\\x94}\\x94h\\n\\x8c\\x05torch\\x94\\x8c\\x06Tensor\\x94\\x93\\x94\\x8a\\x05\\x80)L\\x8b\\x02\\x85\\x94R\\x94su\\x86\\x94\\x86R0.'\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "with io.BytesIO() as file:\n",
    "    cp = cloudpickle.Pickler(file, protocol=None, buffer_callback=None)\n",
    "    cp.dump(lambda y: x + y)\n",
    "    print(file.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d6409d16-a4a3-4dc6-b85b-a2d936310ae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cloudpickle' has no attribute '_BUILTIN_TYPE_NAMES'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[241], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcloudpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_BUILTIN_TYPE_NAMES\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cloudpickle' has no attribute '_BUILTIN_TYPE_NAMES'"
     ]
    }
   ],
   "source": [
    "cloudpickle._BUILTIN_TYPE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4aba483f-ff51-4b55-b8f7-e4fc43445dcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pickler' object has no attribute '_BUILTIN_TYPE_NAMES'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[239], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_BUILTIN_TYPE_NAMES\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pickler' object has no attribute '_BUILTIN_TYPE_NAMES'"
     ]
    }
   ],
   "source": [
    "cp._BUILTIN_TYPE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "532afef2-a146-4a70-a695-5888c5904239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72ce9fca-aecc-4119-8558-3c1e3155eea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchedTensor(lvl=1, bdim=0, value=\n",
      "    tensor([[ 0.5271,  0.5215,  0.9051,  0.2090, -1.5623],\n",
      "            [ 0.3213, -0.0021,  0.1317, -0.9832, -0.6461],\n",
      "            [-0.8264,  0.8084, -0.2842, -0.2385, -1.9357],\n",
      "            [-0.1334,  0.9392,  0.5812, -1.5355, -1.1561]])\n",
      ") BatchedTensor(lvl=1, bdim=0, value=\n",
      "    tensor([[ 1.0543,  1.0431,  1.8101,  0.4179, -3.1245],\n",
      "            [ 0.6425, -0.0042,  0.2634, -1.9664, -1.2922],\n",
      "            [-1.6528,  1.6167, -0.5684, -0.4770, -3.8714],\n",
      "            [-0.2669,  1.8783,  1.1624, -3.0711, -2.3121]])\n",
      ")\n",
      "Tensor\n",
      "BatchedTensor(lvl=1, bdim=0, value=\n",
      "    tensor([[ 0.5271,  0.5215,  0.9051,  0.2090, -1.5623],\n",
      "            [ 0.3213, -0.0021,  0.1317, -0.9832, -0.6461],\n",
      "            [-0.8264,  0.8084, -0.2842, -0.2385, -1.9357],\n",
      "            [-0.1334,  0.9392,  0.5812, -1.5355, -1.1561]])\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot access data pointer of Tensor that doesn't have storage",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m---> 15\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mfunctorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gbmi-UvbjekAV-py3.10/lib/python3.10/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gbmi-UvbjekAV-py3.10/lib/python3.10/site-packages/torch/_functorch/vmap.py:278\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    275\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gbmi-UvbjekAV-py3.10/lib/python3.10/site-packages/torch/_functorch/vmap.py:44\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gbmi-UvbjekAV-py3.10/lib/python3.10/site-packages/torch/_functorch/vmap.py:391\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 391\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m, in \u001b[0;36mfunc\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m u \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# try to save the tensors (the error occurs here)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msomefile.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gbmi-UvbjekAV-py3.10/lib/python3.10/site-packages/torch/serialization.py:629\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 629\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gbmi-UvbjekAV-py3.10/lib/python3.10/site-packages/torch/serialization.py:841\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    839\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[1;32m    840\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[0;32m--> 841\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    843\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gbmi-UvbjekAV-py3.10/lib/python3.10/site-packages/torch/_tensor.py:217\u001b[0m, in \u001b[0;36mTensor.__reduce_ex__\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# Fast path for regular tensor without Python state.\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce_ex_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__reduce_ex__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, proto)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gbmi-UvbjekAV-py3.10/lib/python3.10/site-packages/torch/_tensor.py:382\u001b[0m, in \u001b[0;36mTensor._reduce_ex_internal\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m    371\u001b[0m     args_nested \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;66;03m# NB: values() currently returns the storage as a buffer in an unsafe way.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;66;03m# Ideally, we'd use a private API for this instead. TODO: Switch to this if\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nested_tensor_storage_offsets(),\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_rebuild_nested_tensor, args_nested)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m__torch_dispatch__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39m__torch_dispatch__\n\u001b[1;32m    385\u001b[0m ):\n\u001b[1;32m    386\u001b[0m     arg_wrapper_subclass \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad,\n\u001b[1;32m    395\u001b[0m     )\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_rebuild_wrapper_subclass, arg_wrapper_subclass)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot access data pointer of Tensor that doesn't have storage"
     ]
    }
   ],
   "source": [
    "u = None\n",
    "\n",
    "\n",
    "def func(x: torch.Tensor) -> torch.Tensor:\n",
    "    global u\n",
    "    # some function where we want to debug closely here\n",
    "    y = 2 * x\n",
    "    print(x, y)  # to show x & y are BatchedTensors\n",
    "    print(x.__class__.__name__)\n",
    "    u = x\n",
    "    # try to save the tensors (the error occurs here)\n",
    "    torch.save((x, y), \"somefile.pt\")\n",
    "    return y\n",
    "\n",
    "\n",
    "x = torch.randn((4, 5))\n",
    "y = functorch.vmap(func)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90020ccd-c1d3-47ef-92b2-e76e5129026f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchedTensor(lvl=1, bdim=0, value=\n",
       "    tensor([[ 0.5271,  0.5215,  0.9051,  0.2090, -1.5623],\n",
       "            [ 0.3213, -0.0021,  0.1317, -0.9832, -0.6461],\n",
       "            [-0.8264,  0.8084, -0.2842, -0.2385, -1.9357],\n",
       "            [-0.1334,  0.9392,  0.5812, -1.5355, -1.1561]])\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a91c898-bef7-4c6f-a8b4-897f8f6130fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Either your tensor may have escaped from inside a function being vmapped and this is a user error (see https://pytorch.org/functorch/stable/ux_limitations.html), or there is an internal functorch error in `gen_vmap_plumbing` Please file an issue if it looks like the latter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mu\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Either your tensor may have escaped from inside a function being vmapped and this is a user error (see https://pytorch.org/functorch/stable/ux_limitations.html), or there is an internal functorch error in `gen_vmap_plumbing` Please file an issue if it looks like the latter"
     ]
    }
   ],
   "source": [
    "u[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "512eabaa-785e-448e-824d-9e2c55fade01",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pickler' object has no attribute 'dumps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[177], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m y: x \u001b[38;5;241m+\u001b[39m y)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pickler' object has no attribute 'dumps'"
     ]
    }
   ],
   "source": [
    "cp.dumps(lambda y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fdc56945-1e5c-4996-a1c6-f1bba3273f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x05\\x95\\x1f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x05torch\\x94\\x8c\\x06Tensor\\x94\\x93\\x94\\x8a\\x05P\\x18\\x12l\\x01\\x85\\x94R\\x94.'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloudpickle.dumps(torch.tensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "17fb538e-05c5-4b96-acb7-5fa986ac7d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<lambda>',\n",
       " None,\n",
       " (),\n",
       " b'd\\x01t\\x00\\xa0\\x01\\x87\\x00f\\x01d\\x02d\\x03\\x84\\x08\\xa1\\x01\\x17\\x00S\\x00',\n",
       " (None,\n",
       "  1,\n",
       "  <code object <lambda> at 0x16b294030, file \"/var/folders/y1/33lbjdps12lf6x0csm_rvb5m0000gn/T/ipykernel_95829/1144719411.py\", line 1>,\n",
       "  '<lambda>.<locals>.<lambda>'))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_contents(lambda i: 1 + ein.array(lambda j: A[i, j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c07cda24-8066-4ee0-9cc2-9392ad8b413a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mein\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mein\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/gbmi/gbmi/utils/ein.py:46\u001b[0m, in \u001b[0;36marray\u001b[0;34m(f, sizes)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray\u001b[39m(\n\u001b[1;32m     44\u001b[0m     f: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Tensor], sizes: Optional[List[Optional[\u001b[38;5;28mint\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     45\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msizes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/gbmi/gbmi/utils/ein.py:19\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(f, collect, sizes)\u001b[0m\n\u001b[1;32m     17\u001b[0m dim \u001b[38;5;241m=\u001b[39m dims(sizes\u001b[38;5;241m=\u001b[39m[sizes[\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_args \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 19\u001b[0m     xs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     xs \u001b[38;5;241m=\u001b[39m apply(partial(f, dim), collect, sizes[\u001b[38;5;241m1\u001b[39m:])\n",
      "Cell \u001b[0;32mIn[139], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ein\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28;01mlambda\u001b[39;00m i: \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mein\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Projects/gbmi/gbmi/utils/ein.py:46\u001b[0m, in \u001b[0;36marray\u001b[0;34m(f, sizes)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray\u001b[39m(\n\u001b[1;32m     44\u001b[0m     f: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Tensor], sizes: Optional[List[Optional[\u001b[38;5;28mint\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     45\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msizes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/gbmi/gbmi/utils/ein.py:19\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(f, collect, sizes)\u001b[0m\n\u001b[1;32m     17\u001b[0m dim \u001b[38;5;241m=\u001b[39m dims(sizes\u001b[38;5;241m=\u001b[39m[sizes[\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_args \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 19\u001b[0m     xs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     xs \u001b[38;5;241m=\u001b[39m apply(partial(f, dim), collect, sizes[\u001b[38;5;241m1\u001b[39m:])\n",
      "Cell \u001b[0;32mIn[139], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(j)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ein\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28;01mlambda\u001b[39;00m i: \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m ein\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28;01mlambda\u001b[39;00m j: \u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "ein.array(lambda i: 1 + ein.array(lambda j: A[i, j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ad6de975-dc2c-4da2-8a89-f4b79af58521",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1606187086.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[140], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    f = lambda: ein.\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "f = lambda: ein.\n",
    "\n",
    "ein.array(lambda i: f())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ddd36946-9a2b-4332-b6aa-d56ff49d78c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(functools.partial(lambda x: lambda y: x, 1), functools.partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4ef1ae7e-d4e6-4edc-9d28-3761da913b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function <lambda> at 0x16c789990>, 1)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functools.partial(lambda x: lambda y: x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e4eb16cc-380a-4b23-9ec6-e071879a112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(hash, \"bleh\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "917d649c-9b02-4702-80aa-fbfa2c244930",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "example_kwarg_inputs should be a dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_set_profiling_executor(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m inp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m trace \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gbmi-UvbjekAV-py3.10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:489\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m     dynamo_config_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gbmi-UvbjekAV-py3.10/lib/python3.10/site-packages/torch/_dynamo/external_utils.py:17\u001b[0m, in \u001b[0;36mwrap_inline.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gbmi-UvbjekAV-py3.10/lib/python3.10/site-packages/torch/jit/_trace.py:805\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    803\u001b[0m             example_inputs \u001b[38;5;241m=\u001b[39m example_kwarg_inputs\n\u001b[1;32m    804\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 805\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    807\u001b[0m         func,\n\u001b[1;32m    808\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m: example_inputs},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    817\u001b[0m         _store_inputs\u001b[38;5;241m=\u001b[39m_store_inputs,\n\u001b[1;32m    818\u001b[0m     )\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    823\u001b[0m ):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: example_kwarg_inputs should be a dict"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "conv = torch.nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)\n",
    "\n",
    "#  To avoid dealing with prim::Bailout stuff\n",
    "torch._C._jit_set_profiling_executor(False)\n",
    "\n",
    "inp = torch.rand(1, 3, 224, 224)\n",
    "trace = torch.jit.trace(conv, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33f7d82-c965-4fbf-835d-124632b759d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbmi",
   "language": "python",
   "name": "gbmi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
